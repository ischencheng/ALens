["Embedding is a common technique for analyzing multi-dimensional data. However, the embedded latent space cannot always form significant and interpretable visual structures that foreshadow underlying data patterns. We propose an approach that incorporates human knowledge into data embeddings to improve pattern significance and interpretability. The core idea is (1) concretizing abstract human knowledge as artificial sample labels and (2) adding a classification loss in the embedding network to encode samples’ classes. The approach pulls samples of the same class with similar data features closer in the latent space, leading to more compact (significant) and class-consistent (interpretable) visual structures. We give an embedding network with a customized classification loss to implement the idea and integrate the network into a visualization system to form a workflow that supports flexible knowledge creation and pattern exploration. Patterns found on open datasets in case studies, subjects’ performance in a user study, and quantitative experiment results illustrate the general usability and effectiveness of the approach."]